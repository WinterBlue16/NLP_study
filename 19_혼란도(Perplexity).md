# 19_혼란도(Perplexity)

두 개의 모델 A, B가 있을 때 이 모델의 성능은 어떻게 비교할 수 있을까? 일단은 두 개의 모델을 모두 오타 교정, 기계 번역 등에 사용해보고 해당 업무의 성능을 비교함으로써 평가를 해볼 수 있다. 그러나 성능 비교를 위해 일일히 실제 작업을 시켜보고 정확도를 비교하는 것은 번거롭고, 효율이 떨어지는 일이다. 단적인 예로, 비교해야 하는 모델이 두 개가 아니라 그 이상의 수라면 작업 시간은 측정하기 힘들 정도로 불어날 것이다. <br>

이러한 방식을 외부 평가(extrinsic evaluation)라고 하는데, 이러한 평가보다는 어쩌면 조금 부정확할 수도 있으나 테스트 데이터에 대해서 빠르게 결과를 도출하는 더 간단한 평가 방법이 있다. 바로 모델 내에서 성능을 수치화하여 결과를 내놓는 내부 평가(Intrinsic evaluation)에 해당하는 펄플렉서티(perplexity)이다. 

## 1. 언어 모델의 평가 방법(Evaluation metric) : PPL

펄플렉서티(perplexity), 줄여서 PPL은 언어 모델을 평가하기 위한 내부 평가 지표이다. 조금 근본적인 질문을 하나 던져보자. 왜 perplexity라는 용어를 사용했을까? 영어에서 'perplexed'는 '헷갈리는'과 유사한 의미를 가진다. 그러니 여기서 PPL은 '헷갈리는 정도', '혼란도' 정도로 이해하자. PPL을 처음 배울 때 다소 낯설게 느껴질 수 있는 점이 있다면, PPL은 수치가 높을수록 성능이 좋은 것이 아니라, **수치가 낮을수록** 성능이 좋다는 것을 의미한다는 것이다. <BR>



PPL은 단어의 수로 정규화(normalization)된 테스트 데이터에 대한 확률의 역수이다. PPL을 최소화한다는 것은 문장의 확률을 최대화하는 것과 같다. 문장 W의 길이가 N이라고 하였을 때, PPL은 다음과 같다. 
$$
PPL(W)=P(w_1,w_2,w_3,...,w_N)=
$$
  