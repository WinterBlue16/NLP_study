{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15_언어 모델(Language Model)\n",
    "언어 모델(Language Model)이란 단어 시퀀스(문장)에 확률을 할당하는 모델을 말한다. 어떤 문장들이 있을 때, 기계가 이 문장은 적절해! 이 문장은 말이 안 돼!라고 사람처럼 판단할 수 있다면, 기계가 자연어 처리를 잘 한다고 볼 수 있다. 언어모델은 바로 이런 일을 한다.<br>\n",
    "\n",
    "이 문서에서는 통계에 기반한 전통적인 언어 모델(Statistical Languagel Model, SLM)에 대해서 배운다. 이런 모델은 우리가 실제 사용하는 자연어라고 하기에는 많은 한계가 존재했고, 요즘 들어 인공 신경망이 이러한 한계를 많이 해결하며(GPT, BERT) 통계 기반 언어 모델은 사용 빈도가 많이 줄었다. <br>\n",
    "\n",
    "하지만 그럼에도 여전히 이런 모델에서 배우게 될 n-gram은 자연어 처리 분야에서 활발하게 활용되고 있으며, 통계 기반 방법론에 대한 이해는 언어 모델에 대한 전체적인 시야를 갖는 데 도움을 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 언어 모델이란?\n",
    "다시 설명한다. 언어 모델은 **단어 시퀀스에 확률을 할당(assign)**하는 일을 한다. 이를 조금 풀어서 쓰면, 언어 모델은 가장 자연스러운 단어 시퀀스를 찾아내는 일을 한다고 보면 된다. 단어 시퀀스에 확률을 할당하게 하기 위해 가장 보편적으로 사용되는 방법은 언어 모델이 **이전 단어들이 주어졌을 때, 다음 단어를 예측**하도록 하는 것이다. <br>\n",
    "\n",
    "이와 다른 유형의 언어 모델로는 주어진 양쪽의 단어들로부터 가운데 비어있는 단어를 예측하도록 하는 것이 있다. 이는 마치 고등학교 모의고사에서 문장의 가운데 단어를 비워놓고 어떤 단어인지 맞추는 빈칸 추론 문제와 비슷하다. 이 유형의 언어 모델은 맨 마지막 BERT 문서에서 다루도록 하고, 그 때까지는 이전 단어들로부터 다음 단어를 예측하는 방식에만 집중하도록 한다.<br>\n",
    "\n",
    "언어 모델에 -ing를 붙인 언어 모델링(Language Modeling)은 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업을 말한다. <br>\n",
    "\n",
    "자연어 처리로 유명한 스탠포트대학교에서는 언어 모델을 문법(grammer)라고 비유하기도 한다. 언어 모델이 단어들의 조합이 얼마나 적절한지, 또는 해당 문장이 얼마나 적합한지를 알려주는 일을 하는 것이 마치 문법이 하는 일처럼 보이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
