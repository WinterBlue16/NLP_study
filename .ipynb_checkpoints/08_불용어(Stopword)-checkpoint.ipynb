{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08_불용어(Stopword)\n",
    "갖고 있는 데이터에서 의미 있는 단어 토큰만을 선별하기 위해서는 분석에 있어 큰 도움이 되지 않는 단어 토큰들을 제거하는 작업이 필수적이다.이를 테면, I, my, me, over 등 일부 대명사와 조사, 접미사 같은 단어들은 문장에서 매우 자주 등장하나 실제 의미 분석을 하는데는 큰 도움이 되지 않는다. 이러한 단어들을 **불용어(Stopword)**라 하며, NLTK에서는 100여 개 이상의 불용어를 패키지 내에서 정의하고 있다. \n",
    "<br>\n",
    "물론 불용어는 개발자가 직접 정의할 수도 있다. 여기서는 영어문장에서 NLTK가 정의한 불용어를 제거하는 실습을 하고, 한국어 문장에서 직접 정의한 불용어를 제거해 본다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NLTK에서 불용어 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10] # 불용어 중 10개만 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLTK를 통해서 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example=\"Family is not an important thing. It's everything.\"\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "word_tokens=word_tokenize(example)\n",
    "\n",
    "result=[]\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        result.append(w)\n",
    "        \n",
    "print(word_tokens)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 한국어에서 불용어 제거하기\n",
    "한국어에서 불용어를 제거하는 방법으로 간단하게는 토큰화 후에 조사, 접속사 등을 제거하는 방법이 있다. 하지만 불용어를 제거하려고 하다보면 조사나 접속사와 같은 단어들뿐만 아니라 명사, 형용사와 같은 단어들 중에서도 불용어에 대항하는 단어들이 생기기도 한다. <br>\n",
    "결국 사용자가 직접 불용어 사전을 만들게 되는 경우가 적지 않다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고기를', '아무렇게나', '구우려고', '하면', '안', '돼', '.', '고기라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n",
      "['고기를', '구우려고', '안', '돼', '.', '고기라고', '다', '같은', '게', '.', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "stop_words = \"아무렇게나 아무거나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 하면 아니거든\"\n",
    "# 위의 불용어는 명사가 아닌 단어 중에서 임의로 선정한 것으로 실제 의미있는 선정기준은 아님\n",
    "stop_words=stop_words.split(' ')\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        result.append(w)\n",
    "\n",
    "# 한 줄 요약\n",
    "# result=[word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 링크는 보편적으로 선택할 수 있는 한국어 불용어 리스트이다.다만 절대적인 기준은 아니며 상황에 따라 다른 불용어를 추가할 수 있다. \n",
    "<br>\n",
    "- 참고 링크 1: https://www.ranks.nl/stopwords/korean\n",
    "- 참고 링크 2: https://bab2min.tistory.com/544\n",
    "\n",
    "<br>\n",
    "불용어를 제거하는데 보다 효율적인 방법은 코드 내에서 직접 정의하지 않고, txt파일이나 csv 파일로 미리 불용어를 정리해놓은 후, 이를 불러와 사용하는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
