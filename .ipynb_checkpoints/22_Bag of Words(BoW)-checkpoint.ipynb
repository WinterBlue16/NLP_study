{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22_Bag of Words(BoW)\n",
    "이 문서에서는 단어의 등장 순서를 고려하지 않는, 빈도수 기반의 단어 표현 방법인 Bag of Words에 대해서 학습한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag of Words란?\n",
    "Bag of Words란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법이다. Bag of Words를 직역하면 '단어들의 가방'이라는 의미가 된다. 단어들이 잔뜩 들어있는 가방을 한번 상상해보자. 갖고 있는 어떤 텍스트 문서에 있는 단어들을 모아다가 가방에 전부 집어넣는 것이다. 그리고 나서 이 가방을 흔들어 단어들을 섞어보자. 만약, 해당 문서 안에서 특정 단어가 N번 등장했다면, 가방에는 그 단어가 N개 존재하는 것이다. 당연하지만 가방을 흔들어 단어들이 전부 섞였기 때문에 더 이상 단어의 순서는 중요하지 않게 된다. <br>\n",
    "\n",
    "BoW를 만드는 과정을 아래와 같은 두 가지 과정으로 생각해보자. \n",
    "1) 우선, 각 단어에 고유한 정수 인덱스를 부여한다. \n",
    "2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다. \n",
    "\n",
    "<br>\n",
    "\n",
    "한국어 예제를 통해 BoW에 대해 이해해보자. <br>\n",
    "(1) 우선, 각 단어에 고유한 정수 인덱스를 부여한다. \n",
    "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만든다. <br>\n",
    "\n",
    "한국어 예제를 통해서 BoW에 대해서 이해해보자. <br>\n",
    "**문서 1: 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.**<br>\n",
    "\n",
    "위의 문서 1에 대해서 BoW를 만들어보도록 하자. 아래의 코드는 입력된 문서에 대해서 단어 집합(vocabulary)을 만들어 인덱스를 할당하고, BoW를 만드는 코드이다. 이 코드에 이번에 입력할 것은 문서 1입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt=Okt()\n",
    "\n",
    "token=re.sub(\"(\\.)\", \"\", \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")\n",
    "# 정규 표현식을 통해 온점을 제거하는 정제 작업이다. \n",
    "token=okt.morphs(token)\n",
    "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에 넣는다. \n",
    "\n",
    "word2index={}\n",
    "bow=[]\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)\n",
    "# token을 읽으면서, word2index에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘긴다.\n",
    "    \n",
    "        bow.insert(len(word2index)-1, 1)\n",
    "# BoW 전체에 전부 기본값 1을 넣어줍니다. 단어의 개수는 최소 1개 이상이기 때문입니다.\n",
    "    else:\n",
    "        index=word2index.get(voca)\n",
    "# 재등장하는 단어의 인덱스를 받아온다. \n",
    "        bow[index]=bow[index]+1\n",
    "# 재등장한 단어는 해당하는 인덱스의 위치에 1을 더해준다. (단어의 개수를 세는 것)\n",
    "\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문저1에 각 단어에 대해서 인덱스를 부여한 결과는 첫번째 출력 결과이다. 문서1의 BoW는 두번째 출력 결과이다. 결과를 보면, 물가상승률의 인덱스는 4이며, 문서1에서 물가상승률은 2번 언급되었기 때문에 인덱스 4(다섯번째 값)에 해당하는 값이 2임을 알 수 있다.(원할 경우 한국어에서 불용어에 해당하는 조사들 또한 제거하여 더 정제된 BoW를 만들 수도 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words의 다른 예제들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
